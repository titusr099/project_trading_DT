{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones X_train: (1015, 28)\n",
      "Dimensiones X_test: (30, 28)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos\n",
    "df = pd.read_csv('../../data/processed/JNJ_clean.csv')\n",
    "\n",
    "# Crear conjuntos de entrenamiento y prueba en base a la columna 'Date'\n",
    "train_df = df[df['Date'] <= '2025-02-28']\n",
    "test_df = df[df['Date'] >= '2025-03-01']\n",
    "\n",
    "# Definir las variables de características (X) y objetivo (y)\n",
    "X_train = train_df.drop(columns=['target', 'Close', 'Open', 'High', 'Low', 'Date'])\n",
    "y_train = train_df['target']\n",
    "\n",
    "X_test = test_df.drop(columns=['target', 'Close', 'Open', 'High', 'Low', 'Date'])\n",
    "y_test = test_df['target']\n",
    "\n",
    "# Verificar las dimensiones\n",
    "print(\"Dimensiones X_train:\", X_train.shape)\n",
    "print(\"Dimensiones X_test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluando el modelo: DecisionTree\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.64      0.53        14\n",
      "           1       0.50      0.31      0.38        16\n",
      "\n",
      "    accuracy                           0.47        30\n",
      "   macro avg       0.47      0.48      0.46        30\n",
      "weighted avg       0.48      0.47      0.45        30\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[ 9  5]\n",
      " [11  5]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluando el modelo: RandomForest\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50        14\n",
      "           1       0.56      0.56      0.56        16\n",
      "\n",
      "    accuracy                           0.53        30\n",
      "   macro avg       0.53      0.53      0.53        30\n",
      "weighted avg       0.53      0.53      0.53        30\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[7 7]\n",
      " [7 9]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluando el modelo: AdaBoost\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.50      0.45        14\n",
      "           1       0.46      0.38      0.41        16\n",
      "\n",
      "    accuracy                           0.43        30\n",
      "   macro avg       0.44      0.44      0.43        30\n",
      "weighted avg       0.44      0.43      0.43        30\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[ 7  7]\n",
      " [10  6]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluando el modelo: GradientBoosting\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.57      0.52        14\n",
      "           1       0.54      0.44      0.48        16\n",
      "\n",
      "    accuracy                           0.50        30\n",
      "   macro avg       0.50      0.50      0.50        30\n",
      "weighted avg       0.51      0.50      0.50        30\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[8 6]\n",
      " [9 7]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluando el modelo: LightGBM\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57        14\n",
      "           1       0.62      0.62      0.62        16\n",
      "\n",
      "    accuracy                           0.60        30\n",
      "   macro avg       0.60      0.60      0.60        30\n",
      "weighted avg       0.60      0.60      0.60        30\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[ 8  6]\n",
      " [ 6 10]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluando el modelo: XGBoost\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.64      0.60        14\n",
      "           1       0.64      0.56      0.60        16\n",
      "\n",
      "    accuracy                           0.60        30\n",
      "   macro avg       0.60      0.60      0.60        30\n",
      "weighted avg       0.61      0.60      0.60        30\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[9 5]\n",
      " [7 9]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluando el modelo: CatBoost\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.29      0.40        14\n",
      "           1       0.58      0.88      0.70        16\n",
      "\n",
      "    accuracy                           0.60        30\n",
      "   macro avg       0.62      0.58      0.55        30\n",
      "weighted avg       0.62      0.60      0.56        30\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[ 4 10]\n",
      " [ 2 14]]\n",
      "--------------------------------------------------\n",
      "Comparación global de modelos:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.580357</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.602679</td>\n",
       "      <td>0.602679</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.598214</td>\n",
       "      <td>0.598214</td>\n",
       "      <td>0.598214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.504525</td>\n",
       "      <td>0.504464</td>\n",
       "      <td>0.499444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.477679</td>\n",
       "      <td>0.457014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.436652</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.432703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Modelo  Accuracy  Precision Macro  Recall Macro  F1 Macro\n",
       "6          CatBoost  0.600000         0.625000      0.580357  0.550000\n",
       "5           XGBoost  0.600000         0.602679      0.602679  0.600000\n",
       "4          LightGBM  0.600000         0.598214      0.598214  0.598214\n",
       "1      RandomForest  0.533333         0.531250      0.531250  0.531250\n",
       "3  GradientBoosting  0.500000         0.504525      0.504464  0.499444\n",
       "0      DecisionTree  0.466667         0.475000      0.477679  0.457014\n",
       "2          AdaBoost  0.433333         0.436652      0.437500  0.432703"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Lista de nombres de modelos (deben coincidir con el nombre del archivo .pkl guardado)\n",
    "model_names = [\"DecisionTree\", \"RandomForest\", \"AdaBoost\", \"GradientBoosting\", \"LightGBM\", \"XGBoost\", \"CatBoost\"]\n",
    "\n",
    "# Lista para almacenar los resultados de cada modelo\n",
    "results = []\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(f\"\\nEvaluando el modelo: {model_name}\")\n",
    "    \n",
    "    # Cargar el modelo desde la carpeta de modelos\n",
    "    model_path = f'../../models/{model_name}_JNJ.pkl'\n",
    "    model = joblib.load(model_path)\n",
    "    \n",
    "    # Realizar la predicción en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calcular las métricas globales\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    # Mostrar reporte y matriz de confusión para cada modelo\n",
    "    print(\"Reporte de Clasificación:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Matriz de Confusión:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Guardar los resultados\n",
    "    results.append({\n",
    "        \"Modelo\": model_name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision Macro\": precision,\n",
    "        \"Recall Macro\": recall,\n",
    "        \"F1 Macro\": f1\n",
    "    })\n",
    "\n",
    "# Convertir la lista de resultados a un DataFrame para facilitar la comparación\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=\"Precision Macro\", ascending=False)\n",
    "\n",
    "print(\"Comparación global de modelos:\")\n",
    "results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bolsa_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
